# Тестовое задание Wisebits

## Начало работы

1. Склонируйте репозиторий:

   ```bash
   git clone git@github.com:konstantinx/coffee-feed.git
    ```
2. Перейдите в каталог:

   ```bash
   cd coffee-feed
    ```
3. Установите зависимости:

   ```bash
   pnpm install
    ```
4. Запустите docker контейнер с redis:

   ```bash
   docker run -d --name redis-stack -p 6379:6379 -p 8001:8001 redis/redis-stack:latest
    ```

5. Для запуска API:

   ```bash
   nx run api:serve:production
    ```
6. Для запуска frontend:

   ```bash
   nx run frontend:preview:production
    ```

## Нюансы реализации

Некоторые кейсы выходят за пределы тз и я хотел бы их рассписать

+  Основной идеей было сделать простые сессии и кеширование карточек на их основе. Для оптимизации чтение реализовано через пагинацию.
+ При первом посещении страницы - производится запрос /login. В backend генерируется uid и подписывает через куки запрос.
Таким образом последующие запросы будут осуществляться в рамках одной сессии с полученным хешом.
+ При первом запуске при отсуствии кеша - автоматически создается первый элемент.
+ Если страница будет перезагружена - загрузится по умолчанию только 5 первых элементов в рамках сессии. Остальные итемы нужно подгружать в рамках бесконечного списка.
+ Используются компоненты Skeleton для отображения каркаса загружаемых элементов.
+ Цвет твегов рассчитывается на основе их хеша и побитового умножения

+ Для реализации кеша выбрал Redis. Я считаю это хорошим выбором с учетом требований по конкурентности в тз.
+ Redis отлично подходит для реализации распределенного API лимитера. Я настроил такую возможность для сервера.
+ Я реализовал интерцептор для лимитирования запроса на создание карточки кофе на уровне пользователя.
То есть если пользователь попытается вызвать несколько запросов одновременно в обход фронта, то на уровне сервера он получит блок и ошибку.
Для реализации распределенного блока использовал redis. [OneRequestPerSessionInterceptorf](apps/api/src/interceptors/one-request-per-session.interceptor.ts)
+ В кейсе с запросами на сервер я учитывал, что в теории карточка может придти дважды с одним и тем же id.
Что бы оптимизировать количество запросов и синхронизировать картинки для всех одинаковых карточек в кеше - я сдел их кеширование так же.
При этом через синхронизацию учитывается кейс, когда несколько участников одновременно попытаются сохранить картинку в кеш для одной карточки.
+ Для дополнительной оптимизации в качестве платформы для Nest.js настроил fastify.

## Идеи для улучшения

Я понимаю что многие идеи уходят далеко за время отведенное на тз, но все же хочется их упомянуть

+ Добавить виртуализацию для списка, что позволит еще больше оптимизировать память у клиента.
+ В теории так как список бесконечный и может быть очень большим, но одновременно он простой. Для ускорения доступа к кешу можно
реализовать деление листа на бакеты с смещением в имени ключа. Это избавит нас от сложности перебора большого списка 0(n) и мы смогли бы с константным временем читать паджинированные данные.
+ e2e и unit тесты
+ Текущая реализация блокировок работает с учетом одного инстанса redis. Но можно применить редлок и использовать кластер из инстансов редиса для подобных трюков.

